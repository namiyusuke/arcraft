import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";
import { searchSimilarDocuments } from "@/app/_libs/vectorStore";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const { messages } = await request.json();

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json({ error: "Invalid messages format" }, { status: 400 });
    }

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰é–¢é€£æ–‡æ›¸ã‚’æ¤œç´¢
    const lastUserMessage = messages[messages.length - 1].content;
    let contextInfo = "";
    let debugInfo = {
      query: lastUserMessage,
      searchResults: null as any,
      contextUsed: false,
      error: null as string | null
    };
    
    console.log(`ğŸ” RAGæ¤œç´¢é–‹å§‹ - ã‚¯ã‚¨ãƒª: "${lastUserMessage}"`);
    
    try {
      const similarDocs = await searchSimilarDocuments(lastUserMessage, 3);
      debugInfo.searchResults = similarDocs;
      
      console.log(`ğŸ“Š æ¤œç´¢çµæœ: ${similarDocs?.length || 0}ä»¶`);
      
      if (similarDocs && similarDocs.length > 0) {
        console.log(`ğŸ“Š æ¤œç´¢çµæœã®è©³ç´°åˆ†æ:`);
        similarDocs.forEach((doc, index) => {
          console.log(`ğŸ“„ æ–‡æ›¸${index + 1}:`, {
            content: doc.pageContent.substring(0, 150) + '...',
            contentLength: doc.pageContent.length,
            metadata: doc.metadata,
            // SupabaseVectorStoreã¯é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¿”ã•ãªã„å ´åˆãŒã‚ã‚‹
          });
        });
        
        contextInfo = similarDocs
          .map((doc, index) => `[å‚è€ƒæƒ…å ±${index + 1}]\n${doc.pageContent}`)
          .join('\n\n');
        
        debugInfo.contextUsed = true;
        console.log(`âœ… RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ:`);
        console.log(`   - æ–‡æ›¸æ•°: ${similarDocs.length}`);
        console.log(`   - ç·æ–‡å­—æ•°: ${contextInfo.length}`);
        console.log(`   - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: ${contextInfo.substring(0, 200)}...`);
      } else {
        console.log('âš ï¸  é–¢é€£æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ');
      }
    } catch (error) {
      debugInfo.error = error instanceof Error ? error.message : String(error);
      console.error('âŒ Vector search error:', error);
      // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒãƒ£ãƒƒãƒˆã¯ç¶™ç¶š
    }
    
    const systemMessage = contextInfo 
      ? `ã‚ãªãŸã¯namiã«ã¤ã„ã¦è©³ã—ã„è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

é‡è¦ï¼šä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ã“ã®æƒ…å ±ã‚’å¿…ãšæ´»ç”¨ã—ã¦ã€å…·ä½“çš„ã§è©³ç´°ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

å‚è€ƒæƒ…å ±ï¼š
${contextInfo}

ä¸Šè¨˜ã®å‚è€ƒæƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦å…·ä½“çš„ã§è©³ç´°ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚
å‚è€ƒæƒ…å ±ã«å«ã¾ã‚Œã‚‹å†…å®¹ã‚’ç©æ¥µçš„ã«ä½¿ç”¨ã—ã€ã€Œå‚è€ƒæƒ…å ±ã«ã‚ˆã‚‹ã¨ã€ã‚„ã€Œæƒ…å ±ã«ã‚ˆã‚Œã°ã€ãªã©ã®è¡¨ç¾ã‚’ä½¿ã£ã¦ã€
æƒ…å ±æºã‚’æ˜ç¢ºã«ã—ãªãŒã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚`
      : 'ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬çš„ãªçŸ¥è­˜ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚';

    console.log(`ğŸ¤– ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (${systemMessage.length}æ–‡å­—):`);
    console.log(systemMessage.substring(0, 300) + '...');

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: systemMessage,
        },
        ...messages,
      ],
      max_tokens: 500,
      temperature: 0.7,
    });

    const aiResponse = completion.choices[0]?.message?.content;

    if (!aiResponse) {
      return NextResponse.json({ error: "No response from AI" }, { status: 500 });
    }

    // é–‹ç™ºç’°å¢ƒã§ã®ã¿ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿”ã™
    const response: any = { message: aiResponse };
    
    if (process.env.NODE_ENV === 'development') {
      response.debug = {
        ...debugInfo,
        systemMessageLength: systemMessage.length,
        contextUsed: debugInfo.contextUsed,
        searchResultsCount: debugInfo.searchResults?.length || 0,
      };
      console.log('ğŸ› RAGãƒ‡ãƒãƒƒã‚°æƒ…å ±:', response.debug);
    }
    
    return NextResponse.json(response);
  } catch (error) {
    console.error("OpenAI API error:", error);
    return NextResponse.json({ error: "Internal server error" }, { status: 500 });
  }
}
